<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Monitoring vs Observability: What Actually Matters — SRE Blog</title>
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>

  <header class="header">
    <div class="header-inner">
      <a href="../index.html" class="logo"><span>&gt;_</span> sre.blog</a>
      <nav class="nav">
        <a href="../index.html">Home</a>
        <button class="theme-toggle" aria-label="Toggle theme">&#9790;</button>
      </nav>
      <button class="mobile-menu-btn" aria-label="Menu">&#9776;</button>
    </div>
  </header>

  <main class="article-page">
    <a href="../index.html" class="back-link">&larr; Back to articles</a>

    <div class="article-header">
      <h1>Monitoring vs Observability: What Actually Matters</h1>
      <div class="article-meta">Jan 25, 2026 &middot; 10 min read</div>
      <div class="tags" style="margin-top: 0.75rem;">
        <span class="tag">Monitoring</span>
        <span class="tag">Observability</span>
        <span class="tag">Prometheus</span>
      </div>
    </div>

    <div class="article-content">
      <p>The terms "monitoring" and "observability" are often used interchangeably, but they represent fundamentally different approaches to understanding your systems. Let's break down what each means and why it matters.</p>

      <h2>Monitoring: Knowing What's Broken</h2>
      <p>Monitoring is about collecting predefined metrics and setting up alerts for known failure modes. It answers the question: <strong>"Is this thing working?"</strong></p>
      <p>A typical monitoring stack includes:</p>
      <ul>
        <li><strong>Metrics</strong> — Prometheus, Datadog, CloudWatch</li>
        <li><strong>Dashboards</strong> — Grafana, Kibana</li>
        <li><strong>Alerting</strong> — PagerDuty, OpsGenie</li>
        <li><strong>Health checks</strong> — Uptime monitors, synthetic checks</li>
      </ul>
      <p>Monitoring works well for known-unknowns: failures you can predict and write checks for.</p>

      <h2>Observability: Understanding Why It's Broken</h2>
      <p>Observability goes deeper. It's about being able to ask arbitrary questions about your system's behavior without having to predict those questions in advance. It answers: <strong>"Why is this thing broken?"</strong></p>
      <p>The three pillars of observability:</p>

      <h3>1. Metrics</h3>
      <p>Numeric measurements over time. USE and RED methods give you a solid foundation:</p>
      <pre><code># USE Method (for resources)
- Utilization: % time the resource is busy
- Saturation: amount of queued work
- Errors: count of error events

# RED Method (for services)
- Rate: requests per second
- Errors: failed requests per second
- Duration: latency distribution</code></pre>

      <h3>2. Logs</h3>
      <p>Structured, contextual event records. The key is making them queryable and correlated:</p>
      <pre><code>{
  "timestamp": "2026-01-25T10:30:00Z",
  "level": "error",
  "service": "checkout-api",
  "trace_id": "abc123",
  "message": "payment processing failed",
  "user_id": "user-456",
  "error_code": "TIMEOUT"
}</code></pre>

      <h3>3. Traces</h3>
      <p>Distributed traces show you the full journey of a request across services. They're invaluable for debugging latency issues and understanding service dependencies.</p>

      <h2>Building a Practical Stack</h2>
      <p>You don't need to boil the ocean. Start with what gives you the most signal:</p>
      <ol>
        <li><strong>Start with metrics</strong> — Instrument your services with Prometheus client libraries. Track the RED metrics for every service.</li>
        <li><strong>Add structured logging</strong> — Ensure every log line includes a trace/request ID. Use JSON format for easy querying.</li>
        <li><strong>Introduce tracing gradually</strong> — Start with your most critical user paths. OpenTelemetry makes this easier than ever.</li>
        <li><strong>Build dashboards that tell stories</strong> — Don't create a wall of graphs. Each dashboard should answer a specific question.</li>
      </ol>

      <h2>Common Pitfalls</h2>
      <ul>
        <li><strong>Alert fatigue</strong> — Too many alerts means none get attention. Alert on symptoms, not causes.</li>
        <li><strong>Vanity dashboards</strong> — If nobody looks at a dashboard during incidents, delete it.</li>
        <li><strong>Collecting everything</strong> — High-cardinality metrics will blow up your storage costs. Be intentional about what you collect.</li>
        <li><strong>Ignoring the human side</strong> — The best tooling is useless if your team doesn't know how to use it during an incident.</li>
      </ul>

      <h2>Conclusion</h2>
      <p>Monitoring tells you <em>that</em> something is wrong. Observability helps you understand <em>why</em>. You need both. Start simple, iterate based on real incidents, and always optimize for reducing mean time to resolution (MTTR).</p>
    </div>
  </main>

  <footer class="footer">
    <p>&copy; 2026 sre.blog &mdash; Built with simplicity in mind.</p>
  </footer>

  <script src="../js/main.js"></script>
</body>
</html>
